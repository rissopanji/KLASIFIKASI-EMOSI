{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **06. Transformasi Data (Data Transformation)**\n",
    "\n",
    "---\n",
    "- Mengubah ke refesentasi vektor\n",
    "\n",
    "- Membagi data ke datavalid, data testing, dan data training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '../05. Pra-pemrosesan Data (Data Preprocessing)/Dataset_Clean/Dataset_Clean.csv', \n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '../06. Transformasi Data (Data Transformation)/Data_Split/train_data.csv', \n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Word Referesentasi (Word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Membentuk model Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['tweet'].apply(eval).tolist()\n",
    "\n",
    "word2vec_model = Word2Vec(sentences, vector_size=8, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mengubah Teks menjadi Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEMP\\miniconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\TEMP\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def tweet_to_vector(tweet, model):\n",
    "    words = eval(tweet)  \n",
    "    vector = np.mean([model.wv[word] for word in words if word in model.wv and word != '<pad>'], axis=0)\n",
    "    if isinstance(vector, np.ndarray): \n",
    "        return vector\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  \n",
    "\n",
    "data['tweet_vector'] = data['tweet'].apply(lambda x: tweet_to_vector(x, word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31265</td>\n",
       "      <td>['pemilu', 'momen', 'bersejarah', 'keseluruhan...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[-0.20913523, -2.1562426, 0.886566, 2.5301132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>['betul', 'juga', 'mikinya', 'kalau', 'waktu',...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[-0.9321435, -1.1031287, 1.7772691, 3.0841658,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4289</td>\n",
       "      <td>['ngeri', 'sangat', 'jelas', 'positive', 'nong...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[-1.2073029, -0.83843553, 1.5596131, 1.811603,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26820</td>\n",
       "      <td>['yang', 'salah', 'cara', 'berpikir', 'yang', ...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[0.10634192, -1.0936391, 0.24539249, 4.938823,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8377</td>\n",
       "      <td>['acara', 'nya', 'seru', 'bange', 'waktu', 'ka...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[-1.4973531, -0.8356001, 1.1920638, 2.6439862,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32734</th>\n",
       "      <td>6268</td>\n",
       "      <td>['sopaa', 'cuz', 'akuu', 'suka', 'sekali', 'ju...</td>\n",
       "      <td>Love</td>\n",
       "      <td>[-1.4871202, -0.9737764, 1.7366459, 2.8337927,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32735</th>\n",
       "      <td>19482</td>\n",
       "      <td>['pak', 'anies', 'baswedan', 'cawapres', 'puny...</td>\n",
       "      <td>Love</td>\n",
       "      <td>[-2.3848987, -2.018673, 2.7379007, 3.4556708, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32736</th>\n",
       "      <td>39352</td>\n",
       "      <td>['ngecek', 'link', 'ulang', 'benar', 'timnas',...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[-2.643066, -1.0617319, 3.4989257, 2.2979307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32737</th>\n",
       "      <td>29727</td>\n",
       "      <td>['biarpun', 'tim', 'mati', 'matian', 'bekerja'...</td>\n",
       "      <td>Anger</td>\n",
       "      <td>[-0.5136224, -0.4523462, 0.5335757, 1.5281961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32738</th>\n",
       "      <td>3086</td>\n",
       "      <td>['jengkelnya', 'semuanya', 'sih', 'mbulet', 'b...</td>\n",
       "      <td>Anger</td>\n",
       "      <td>[-1.3355953, -0.092395954, 0.95422053, 1.97926...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32739 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              tweet    label  \\\n",
       "0           31265  ['pemilu', 'momen', 'bersejarah', 'keseluruhan...      Joy   \n",
       "1             316  ['betul', 'juga', 'mikinya', 'kalau', 'waktu',...  Neutral   \n",
       "2            4289  ['ngeri', 'sangat', 'jelas', 'positive', 'nong...     Fear   \n",
       "3           26820  ['yang', 'salah', 'cara', 'berpikir', 'yang', ...      Sad   \n",
       "4            8377  ['acara', 'nya', 'seru', 'bange', 'waktu', 'ka...      Joy   \n",
       "...           ...                                                ...      ...   \n",
       "32734        6268  ['sopaa', 'cuz', 'akuu', 'suka', 'sekali', 'ju...     Love   \n",
       "32735       19482  ['pak', 'anies', 'baswedan', 'cawapres', 'puny...     Love   \n",
       "32736       39352  ['ngecek', 'link', 'ulang', 'benar', 'timnas',...      Joy   \n",
       "32737       29727  ['biarpun', 'tim', 'mati', 'matian', 'bekerja'...    Anger   \n",
       "32738        3086  ['jengkelnya', 'semuanya', 'sih', 'mbulet', 'b...    Anger   \n",
       "\n",
       "                                            tweet_vector  \n",
       "0      [-0.20913523, -2.1562426, 0.886566, 2.5301132,...  \n",
       "1      [-0.9321435, -1.1031287, 1.7772691, 3.0841658,...  \n",
       "2      [-1.2073029, -0.83843553, 1.5596131, 1.811603,...  \n",
       "3      [0.10634192, -1.0936391, 0.24539249, 4.938823,...  \n",
       "4      [-1.4973531, -0.8356001, 1.1920638, 2.6439862,...  \n",
       "...                                                  ...  \n",
       "32734  [-1.4871202, -0.9737764, 1.7366459, 2.8337927,...  \n",
       "32735  [-2.3848987, -2.018673, 2.7379007, 3.4556708, ...  \n",
       "32736  [-2.643066, -1.0617319, 3.4989257, 2.2979307, ...  \n",
       "32737  [-0.5136224, -0.4523462, 0.5335757, 1.5281961,...  \n",
       "32738  [-1.3355953, -0.092395954, 0.95422053, 1.97926...  \n",
       "\n",
       "[32739 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalisasi fitur numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'numeric_feature' in data.columns:\n",
    "    scaler = StandardScaler()\n",
    "    data['normalized_numeric_feature'] = scaler.fit_transform(data[['numeric_feature']])\n",
    "\n",
    "    data['features'] = data.apply(lambda row: np.concatenate((row['tweet_vector'], [row['normalized_numeric_feature']])), axis=1)\n",
    "else:\n",
    "\n",
    "    data['features'] = data['tweet_vector']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_vector</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['pengabdian', 'terpuji', 'meskipun', 'terliha...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[1.1716549, -0.32019183, -0.52275145, -1.14394...</td>\n",
       "      <td>[1.1716549, -0.32019183, -0.52275145, -1.14394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['baru', 'mengirim', 'foto', '&lt;pad&gt;', '&lt;pad&gt;',...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[2.0060577, -0.41663948, -2.1723745, -1.693770...</td>\n",
       "      <td>[2.0060577, -0.41663948, -2.1723745, -1.693770...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['apa', 'kabar', 'dunia', 'twitter', 'masihkah...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[1.59231, -0.48822427, -0.5230446, -1.1739731,...</td>\n",
       "      <td>[1.59231, -0.48822427, -0.5230446, -1.1739731,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['yah', 'gimana', 'sih', 'yaudah', 'susul', 's...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[1.9332774, -1.4755193, -1.7834133, -1.4112929...</td>\n",
       "      <td>[1.9332774, -1.4755193, -1.7834133, -1.4112929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['ka', 'dorg', 'suro', 'beli', 'medium', 'set'...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.6079169, -0.23392268, -1.0948995, -0.879356...</td>\n",
       "      <td>[0.6079169, -0.23392268, -1.0948995, -0.879356...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>28710</td>\n",
       "      <td>['ingin', 'sangat', 'nih', 'daerah', 'jakarta'...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[2.7875695, -1.5056438, -2.1028328, -2.1826487...</td>\n",
       "      <td>[2.7875695, -1.5056438, -2.1028328, -2.1826487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>28711</td>\n",
       "      <td>['selamat', 'hari', 'raya', 'tri', 'suci', 'wa...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[-0.43041828, 0.9478071, 0.070903234, -1.32057...</td>\n",
       "      <td>[-0.43041828, 0.9478071, 0.070903234, -1.32057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>28712</td>\n",
       "      <td>['kandungan', 'serat', 'passion', 'fruit', 'ma...</td>\n",
       "      <td>Love</td>\n",
       "      <td>[1.0247041, 0.12736644, -0.28464705, -1.146567...</td>\n",
       "      <td>[1.0247041, 0.12736644, -0.28464705, -1.146567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>28713</td>\n",
       "      <td>['selamat', 'memperingati', 'hari', 'kebangkit...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[0.3818012, 1.2018754, -0.13466965, -1.4089928...</td>\n",
       "      <td>[0.3818012, 1.2018754, -0.13466965, -1.4089928...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28714</th>\n",
       "      <td>28714</td>\n",
       "      <td>['olive', 'oil', 'digunakan', 'mengobati', 'ku...</td>\n",
       "      <td>Love</td>\n",
       "      <td>[0.51738876, 0.23886745, -0.21785624, -0.90159...</td>\n",
       "      <td>[0.51738876, 0.23886745, -0.21785624, -0.90159...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28715 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              tweet    label  \\\n",
       "0               0  ['pengabdian', 'terpuji', 'meskipun', 'terliha...  Neutral   \n",
       "1               1  ['baru', 'mengirim', 'foto', '<pad>', '<pad>',...  Neutral   \n",
       "2               2  ['apa', 'kabar', 'dunia', 'twitter', 'masihkah...  Neutral   \n",
       "3               3  ['yah', 'gimana', 'sih', 'yaudah', 'susul', 's...  Neutral   \n",
       "4               4  ['ka', 'dorg', 'suro', 'beli', 'medium', 'set'...  Neutral   \n",
       "...           ...                                                ...      ...   \n",
       "28710       28710  ['ingin', 'sangat', 'nih', 'daerah', 'jakarta'...  Neutral   \n",
       "28711       28711  ['selamat', 'hari', 'raya', 'tri', 'suci', 'wa...      Joy   \n",
       "28712       28712  ['kandungan', 'serat', 'passion', 'fruit', 'ma...     Love   \n",
       "28713       28713  ['selamat', 'memperingati', 'hari', 'kebangkit...      Joy   \n",
       "28714       28714  ['olive', 'oil', 'digunakan', 'mengobati', 'ku...     Love   \n",
       "\n",
       "                                            tweet_vector  \\\n",
       "0      [1.1716549, -0.32019183, -0.52275145, -1.14394...   \n",
       "1      [2.0060577, -0.41663948, -2.1723745, -1.693770...   \n",
       "2      [1.59231, -0.48822427, -0.5230446, -1.1739731,...   \n",
       "3      [1.9332774, -1.4755193, -1.7834133, -1.4112929...   \n",
       "4      [0.6079169, -0.23392268, -1.0948995, -0.879356...   \n",
       "...                                                  ...   \n",
       "28710  [2.7875695, -1.5056438, -2.1028328, -2.1826487...   \n",
       "28711  [-0.43041828, 0.9478071, 0.070903234, -1.32057...   \n",
       "28712  [1.0247041, 0.12736644, -0.28464705, -1.146567...   \n",
       "28713  [0.3818012, 1.2018754, -0.13466965, -1.4089928...   \n",
       "28714  [0.51738876, 0.23886745, -0.21785624, -0.90159...   \n",
       "\n",
       "                                                features  \n",
       "0      [1.1716549, -0.32019183, -0.52275145, -1.14394...  \n",
       "1      [2.0060577, -0.41663948, -2.1723745, -1.693770...  \n",
       "2      [1.59231, -0.48822427, -0.5230446, -1.1739731,...  \n",
       "3      [1.9332774, -1.4755193, -1.7834133, -1.4112929...  \n",
       "4      [0.6079169, -0.23392268, -1.0948995, -0.879356...  \n",
       "...                                                  ...  \n",
       "28710  [2.7875695, -1.5056438, -2.1028328, -2.1826487...  \n",
       "28711  [-0.43041828, 0.9478071, 0.070903234, -1.32057...  \n",
       "28712  [1.0247041, 0.12736644, -0.28464705, -1.146567...  \n",
       "28713  [0.3818012, 1.2018754, -0.13466965, -1.4089928...  \n",
       "28714  [0.51738876, 0.23886745, -0.21785624, -0.90159...  \n",
       "\n",
       "[28715 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./Data_Transformed/data_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Membagi Dataset (Data Split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7  # 70% untuk training\n",
    "validation_ratio = 0.2  # 20% dari sisa 30% untuk validation, 10% untuk testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membagi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 32739\n",
      "Validation set size: 7015\n",
      "Test set size: 7016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Membaca dataset\n",
    "data = pd.read_csv(\n",
    "    '../05. Pra-pemrosesan Data (Data Preprocessing)/Dataset_Clean/Dataset_Clean.csv', \n",
    "    sep=\",\"\n",
    ")\n",
    "\n",
    "# Memisahkan fitur dan label\n",
    "X = data.drop('label', axis=1)  # Ganti 'label' dengan nama kolom label Anda\n",
    "y = data['label']  # Ganti 'label' dengan nama kolom label Anda\n",
    "\n",
    "# Pembagian data menjadi training dan temporary set (untuk validation dan test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Pembagian temporary set menjadi validation dan test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Menyimpan dataset yang telah dibagi ke direktori\n",
    "output_dir = \"./Data_Split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Menyimpan training set\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv(os.path.join(output_dir, 'train_data.csv'), index=False)\n",
    "\n",
    "# Menyimpan validation set\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "val_data.to_csv(os.path.join(output_dir, 'val_data.csv'), index=False)\n",
    "\n",
    "# Menyimpan test set\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv(os.path.join(output_dir, 'test_data.csv'), index=False)\n",
    "\n",
    "# Menampilkan ukuran setiap set\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Validation set size: {X_val.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'yang':\n",
      "[-1.3604424  -1.6698306   2.387328    6.5467176  -0.40345243 -1.5080339\n",
      "  5.1472936  -1.750812  ]\n",
      "Vector for 'salah':\n",
      "[-0.9371133 -2.4091237  0.6481962  7.5211425  0.8512062 -1.1003132\n",
      "  4.120552  -3.2365217]\n",
      "Vector for 'cara':\n",
      "[-1.175257   -1.6943682   1.8103284   4.0345016   0.26900327 -1.9489814\n",
      "  4.272454   -0.93799895]\n",
      "Vector for 'berpikir':\n",
      "[-0.45759773 -0.5999026   0.33058885  1.4528106   0.2907456  -0.34023815\n",
      "  1.4839174   0.00278315]\n",
      "Vector for 'yang':\n",
      "[-1.3604424  -1.6698306   2.387328    6.5467176  -0.40345243 -1.5080339\n",
      "  5.1472936  -1.750812  ]\n",
      "Vector for 'berperang':\n",
      "[ 0.24257535 -0.1995796  -0.09928071  0.6351126   0.5050839  -0.01318477\n",
      "  0.3345605   0.04873794]\n",
      "Vector for 'melawan':\n",
      "[-0.09093627 -0.740151    0.19343987  2.5331702   0.9392481  -0.5056161\n",
      "  1.8712153   0.13731764]\n",
      "Vector for 'penjajahan':\n",
      "[ 0.73953533 -0.31891137  0.1083969   1.5802063   0.9622953   0.0764325\n",
      "  0.98203266  0.31435028]\n",
      "Vector for 'israel':\n",
      "[ 3.238653   1.3271939 -1.9601473  6.81162    6.6287913  2.8193913\n",
      "  4.450901   5.041883 ]\n",
      "Vector for 'bukan':\n",
      "[ 0.32975087 -0.9126264   2.6854353   6.481702    0.68649656 -1.499394\n",
      "  4.586777   -2.3691132 ]\n",
      "Vector for 'hamas':\n",
      "[ 3.117265   1.3925694 -1.5287067  5.6747975  3.5135763  1.5475599\n",
      "  2.1059039  1.9382585]\n",
      "Vector for 'seluruh':\n",
      "[ 1.95856   -4.0825014  0.3864133  2.9536085  3.2379951 -1.4265138\n",
      "  3.6755898 -1.0216459]\n",
      "Vector for 'rakyat':\n",
      "[ 2.2987485  -3.1089008   1.6391641   5.0483146   2.5332353  -0.16454202\n",
      "  7.512778   -4.324969  ]\n",
      "Vector for 'palestina':\n",
      "[ 6.0608196  -2.6752424   0.16787171  9.475074    1.2789841   3.1116714\n",
      "  5.4912934   0.17917274]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('../06. Transformasi Data (Data Transformation)/Data_Split/train_data.csv', sep=\",\")\n",
    "\n",
    "# Convert the 'tweet' column from string representation of lists to actual lists\n",
    "data['tweet'] = data['tweet'].apply(ast.literal_eval)\n",
    "\n",
    "# Extract the sentences\n",
    "sentences = data['tweet'].tolist()\n",
    "\n",
    "# Train Word2Vec model with vector size of 8\n",
    "model = Word2Vec(sentences, vector_size=8, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get word vectors\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Define the list of words to check\n",
    "words = ['yang', 'salah', 'cara', 'berpikir', 'yang', 'berperang', 'melawan', 'penjajahan', 'israel', 'bukan', 'hamas', 'seluruh', 'rakyat', 'palestina']\n",
    "\n",
    "# Check if each word is in the vocabulary and print its vector if present\n",
    "for word in words:\n",
    "    if word in word_vectors:\n",
    "        print(f\"Vector for '{word}':\\n{word_vectors[word]}\")\n",
    "    else:\n",
    "        print(f\"Word '{word}' not found in the vocabulary.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
