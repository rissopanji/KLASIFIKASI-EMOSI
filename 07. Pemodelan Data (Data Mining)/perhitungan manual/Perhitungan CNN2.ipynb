{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inisiasi Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Embeddings:\n",
      " [[-1.36 -1.66  2.38  6.54 -0.4  -1.5   5.1  -1.75]\n",
      " [-0.94 -2.41  0.65  7.52  0.85 -1.1   4.12 -3.24]\n",
      " [-0.46 -0.6   0.33  1.45  0.29 -0.34  1.48  0.  ]\n",
      " [-1.36 -1.67  2.39  6.55 -0.4  -1.51  5.15 -1.75]\n",
      " [ 0.24 -0.2  -0.1   0.64  0.51 -0.01  0.33  0.05]\n",
      " [-0.09 -0.74  0.19  2.53  0.94 -0.51  1.87  0.14]\n",
      " [ 0.74 -0.32  0.11  1.58  0.96  0.08  0.98  0.31]\n",
      " [ 3.24  1.33 -1.96  6.81  6.63  2.82  4.45  5.04]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of words limited to 22\n",
    "words = ['nikmati', 'senang', 'bareng', 'teman', 'tetap', 'produktif', 'buat', 'bekerja', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
    "\n",
    "# Dictionary of embeddings\n",
    "embeddings = {\n",
    "    'nikmati': [-1.36, -1.66, 2.38, 6.54, -0.40, -1.5, 5.1, -1.75],\n",
    "    'senang': [-0.94, -2.41, 0.65, 7.52, 0.85, -1.10, 4.12, -3.24],\n",
    "    'bareng': [-0.46, -0.60, 0.33, 1.45, 0.29, -0.34, 1.48, 0.00],\n",
    "    'teman': [-1.36, -1.67, 2.39, 6.55, -0.40, -1.51, 5.15, -1.75],\n",
    "    'tetap': [0.24, -0.20, -0.10, 0.64, 0.51, -0.01, 0.33, 0.05],\n",
    "    'produktif': [-0.09, -0.74, 0.19, 2.53, 0.94, -0.51, 1.87, 0.14],\n",
    "    'buat': [0.74, -0.32, 0.11, 1.58, 0.96, 0.08, 0.98, 0.31],\n",
    "    'bekerja': [3.24, 1.33, -1.96, 6.81, 6.63, 2.82, 4.45, 5.04],\n",
    "    '<pad>': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "# Generate embeddings for the word list\n",
    "final_embeddings = np.array([embeddings[word] for word in words])\n",
    "\n",
    "print(\"Final Embeddings:\\n\", final_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution Output Shape: (22, 128)\n",
      "Convolution Output:\n",
      " [[10.67848718  9.20679402  0.58681391 ... 11.46108695 17.86804459\n",
      "  15.83426501]\n",
      " [ 7.79326065  8.60276319  4.45801443 ... 10.49438166 19.61652472\n",
      "  15.06051745]\n",
      " [11.16965034  9.89511638  4.04394125 ...  9.66217265 10.47722164\n",
      "  10.00835689]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Define a filter\n",
    "num_filters = 128\n",
    "kernel_size = 5\n",
    "input_channels = final_embeddings.shape[1]\n",
    "filters = np.random.rand(num_filters, kernel_size, input_channels)\n",
    "\n",
    "# Convolution operation\n",
    "def convolution(embeddings, filters):\n",
    "    conv_output = np.zeros((embeddings.shape[0], num_filters))\n",
    "    for f in range(num_filters):\n",
    "        for i in range(embeddings.shape[0] - kernel_size + 1):\n",
    "            segment = embeddings[i:i+kernel_size]\n",
    "            conv_result = np.sum(segment * filters[f])\n",
    "            conv_output[i, f] = conv_result\n",
    "    return conv_output\n",
    "\n",
    "conv_output = convolution(final_embeddings, filters)\n",
    "\n",
    "print(\"Convolution Output Shape:\", conv_output.shape)\n",
    "print(\"Convolution Output:\\n\", conv_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.85534672, 0.64842836, 0.03096075, ..., 0.44195843,\n",
       "         0.29006436, 0.48695636],\n",
       "        [0.01289663, 0.67800411, 0.30878311, ..., 0.60747222,\n",
       "         0.72780657, 0.25601188],\n",
       "        [0.62181388, 0.57330259, 0.05996161, ..., 0.38908518,\n",
       "         0.82654894, 0.44574168],\n",
       "        [0.61505763, 0.79286451, 0.55688229, ..., 0.67190694,\n",
       "         0.83347168, 0.27683466],\n",
       "        [0.00911506, 0.23117706, 0.18512836, ..., 0.85763986,\n",
       "         0.32926598, 0.93292564]],\n",
       "\n",
       "       [[0.14111073, 0.25712964, 0.90087368, ..., 0.78485264,\n",
       "         0.55083012, 0.18128982],\n",
       "        [0.05704978, 0.64577111, 0.41197533, ..., 0.18244205,\n",
       "         0.62688888, 0.50565689],\n",
       "        [0.71894334, 0.18776929, 0.87552553, ..., 0.21735509,\n",
       "         0.00803255, 0.11751525],\n",
       "        [0.90348196, 0.35635498, 0.001667  , ..., 0.07509205,\n",
       "         0.50392834, 0.43002397],\n",
       "        [0.1718355 , 0.406734  , 0.79247899, ..., 0.7843818 ,\n",
       "         0.88837053, 0.57840054]],\n",
       "\n",
       "       [[0.51375656, 0.7950316 , 0.95140586, ..., 0.94304984,\n",
       "         0.2563401 , 0.99672201],\n",
       "        [0.50038049, 0.71350573, 0.26728144, ..., 0.81171885,\n",
       "         0.57647287, 0.87147769],\n",
       "        [0.89337926, 0.51228639, 0.33585135, ..., 0.88588899,\n",
       "         0.83896209, 0.63352332],\n",
       "        [0.13917779, 0.49483311, 0.65838838, ..., 0.84586046,\n",
       "         0.34469778, 0.57754591],\n",
       "        [0.78844588, 0.34907334, 0.13299815, ..., 0.069996  ,\n",
       "         0.96697134, 0.38226633]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.95051556, 0.81385518, 0.75082373, ..., 0.99685863,\n",
       "         0.57212476, 0.81730683],\n",
       "        [0.17972945, 0.02367074, 0.13874183, ..., 0.59445218,\n",
       "         0.19397062, 0.14810238],\n",
       "        [0.40180559, 0.47899913, 0.63372499, ..., 0.24082142,\n",
       "         0.27718305, 0.96789713],\n",
       "        [0.9057737 , 0.52294071, 0.53462539, ..., 0.85502818,\n",
       "         0.65245469, 0.90486232],\n",
       "        [0.56774985, 0.08963842, 0.1989278 , ..., 0.03185095,\n",
       "         0.76562528, 0.28341178]],\n",
       "\n",
       "       [[0.75918093, 0.01575887, 0.49170263, ..., 0.04893569,\n",
       "         0.77338258, 0.35400363],\n",
       "        [0.30708012, 0.18647995, 0.09662321, ..., 0.93474656,\n",
       "         0.43054958, 0.46143328],\n",
       "        [0.61226322, 0.52611144, 0.82034244, ..., 0.76869388,\n",
       "         0.88212675, 0.28773954],\n",
       "        [0.03518719, 0.87779484, 0.11641088, ..., 0.1828239 ,\n",
       "         0.62000058, 0.22852179],\n",
       "        [0.99800352, 0.59295489, 0.23732337, ..., 0.35096056,\n",
       "         0.81595172, 0.9888719 ]],\n",
       "\n",
       "       [[0.17328268, 0.60389589, 0.24331446, ..., 0.27887327,\n",
       "         0.40936859, 0.92360716],\n",
       "        [0.40115387, 0.06790502, 0.07987703, ..., 0.46946151,\n",
       "         0.30490552, 0.63021883],\n",
       "        [0.18958702, 0.41541017, 0.29105238, ..., 0.58458893,\n",
       "         0.55101793, 0.29108533],\n",
       "        [0.37172996, 0.93551572, 0.68961758, ..., 0.12709391,\n",
       "         0.41578406, 0.45334215],\n",
       "        [0.7478022 , 0.51023092, 0.30460542, ..., 0.85785081,\n",
       "         0.55944324, 0.40212363]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU Output Shape: (22, 128)\n",
      "ReLU Output:\n",
      " [[10.67848718  9.20679402  0.58681391 ... 11.46108695 17.86804459\n",
      "  15.83426501]\n",
      " [ 7.79326065  8.60276319  4.45801443 ... 10.49438166 19.61652472\n",
      "  15.06051745]\n",
      " [11.16965034  9.89511638  4.04394125 ...  9.66217265 10.47722164\n",
      "  10.00835689]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# ReLU activation\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "relu_output = relu(conv_output)\n",
    "\n",
    "print(\"ReLU Output Shape:\", relu_output.shape)\n",
    "print(\"ReLU Output:\\n\", relu_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling Output Shape: (11, 128)\n",
      "Pooling Output:\n",
      " [[10.67848718  9.20679402  4.45801443 ... 11.46108695 19.61652472\n",
      "  15.83426501]\n",
      " [20.36808029 25.46340654 17.62362897 ... 22.46157915 31.79565703\n",
      "  31.47100482]\n",
      " [22.22906127 20.77170084 21.70847748 ... 21.83888484 21.9809792\n",
      "  17.14633349]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Max pooling operation\n",
    "def max_pooling(x, pool_size, stride):\n",
    "    pool_output = []\n",
    "    for i in range(0, len(x) - pool_size + 1, stride):\n",
    "        pool_segment = x[i:i+pool_size]\n",
    "        pool_result = np.max(pool_segment, axis=0)\n",
    "        pool_output.append(pool_result)\n",
    "    return np.array(pool_output)\n",
    "\n",
    "pool_output = max_pooling(relu_output, 2, 2)\n",
    "\n",
    "print(\"Pooling Output Shape:\", pool_output.shape)\n",
    "print(\"Pooling Output:\\n\", pool_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Softmax Output with Emotion Labels:\n",
      "joy: 0.0000\n",
      "sad: 0.0000\n",
      "fear: 0.0000\n",
      "anger: 0.0000\n",
      "neutral: 0.0000\n",
      "love: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Softmax function\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtracting np.max(x) for numerical stability\n",
    "    return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "# Assuming we directly classify using pooled features, we need to reduce dimensions to match class number\n",
    "output_weights = np.random.rand(pool_output.shape[1], 6)  # Output weights for 6 classes\n",
    "output_bias = np.random.rand(6)  # Output bias for 6 classes\n",
    "\n",
    "# Output layer computation\n",
    "output = np.dot(pool_output.mean(axis=0), output_weights) + output_bias\n",
    "\n",
    "softmax_output = softmax(output)\n",
    "\n",
    "emotion_labels = ['joy', 'sad', 'fear', 'anger', 'neutral', 'love']\n",
    "\n",
    "# Print output with emotion labels\n",
    "print(\"\\nSoftmax Output with Emotion Labels:\")\n",
    "for label, prob in zip(emotion_labels, softmax_output):\n",
    "    print(f\"{label}: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
